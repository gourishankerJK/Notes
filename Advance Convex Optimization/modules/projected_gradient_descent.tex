\section{Projected Gradient Descent}
\begin{definition}[Projection onto a convex set]\label{def:projection}
    Let $\bb{X} \subset \bb{R}^n$ be nonempty, closed, and convex.
    The projection operator $\Pi_{\bb{X}} : \bb{R}^n \to \bb{X}$ is defined by
    \[
        \Pi_{\bb{X}}(\bd{z})
        :=
        \arg\min_{\bd{x} \in \bb{X}}
        \|\bd{x} - \bd{z}\|_2.
    \]
\end{definition}
\begin{proposition}[Properties of the projection]\label{prop:projection}
    Let $\bb{X} \subset \bb{R}^n$ be closed and convex.
    Then:
    \begin{enumerate}
        \item $\Pi_{\bb{X}}$ is well-defined and single-valued.
        \item $\Pi_{\bb{X}}$ is nonexpansive:
              \[
                  \|\Pi_{\bb{X}}(\bd{x}) - \Pi_{\bb{X}}(\bd{y})\|_2
                  \le
                  \|\bd{x} - \bd{y}\|_2.
              \]
        \item (Projection inequality)
              \[
                  \langle \bd{z} - \Pi_{\bb{X}}(\bd{z}),
                  \bd{x} - \Pi_{\bb{X}}(\bd{z}) \rangle \le 0,
                  \quad \forall \bd{x} \in \bb{X}.
              \]
    \end{enumerate}
\end{proposition}
\begin{proof}[Proof of (1): Existence]
    Let $\mathcal{C} \subset \bb{R}^n$ be nonempty, closed, and convex, and fix
    $\bd{x} \in \bb{R}^n$.
    Choose any point $\bd{x}_0 \in \mathcal{C}$ and consider the problem:
    \[
        \min_{\bd{z} \in \mathcal{C}} \frac12 \|\bd{z} - \bd{x}\|_2^2.
    \]

    Set
    \[
        R := \|\bd{x} - \bd{x}_0\|_2
        \quad \text{and} \quad
        \mathcal{K} := \mathcal{C} \cap \overline{B}(\bd{x}, R),
    \]
    where $\overline{B}(\bd{x}, R)$ denotes the closed ball centered at
    $\bd{x}$ with radius $R$.

    For any $\bd{z} \in \mathcal{C}$ such that
    $\bd{z} \notin \mathcal{K}$, we must have $\|\bd{z} - \bd{x}\|_2 > R$.
    Substituting $R$, this implies:
    \[
        \frac12 \|\bd{z} - \bd{x}\|_2^2
        >
        \frac12 \|\bd{x}_0 - \bd{x}\|_2^2.
    \]
    Since $\bd{x}_0 \in \mathcal{K}$ achieves a strictly lower objective value,
    no point outside $\mathcal{K}$ can be a minimizer.
    Therefore,
    \[
        \arg\min_{\bd{z} \in \mathcal{C}}
        \frac12 \|\bd{z} - \bd{x}\|_2^2
        =
        \arg\min_{\bd{z} \in \mathcal{K}}
        \frac12 \|\bd{z} - \bd{x}\|_2^2.
    \]

    The set $\mathcal{K}$ is the intersection of a closed set $\mathcal{C}$ and a closed, bounded ball,
    so $\mathcal{K}$ is closed and bounded (hence compact).
    Since the function
    \[
        \bd{z} \mapsto \frac12 \|\bd{z} - \bd{x}\|_2^2
    \]
    is continuous, it attains its minimum on the compact set $\mathcal{K}$ by the
    \emph{Weierstrass extreme value theorem}.
    Thus, a minimizer exists.\\
    \textbf{Proof of (2): Uniqueness} \red{TODO}
\end{proof}

\begin{algorithmblock}[title=Projected Gradient Descent]
    \label{alg:pgd}
    \textbf{Input:} $f$, $C$, $\gamma$, $\bd{x}_0$ \\
    \textbf{for} $k = 0,1,2,\dots$ \textbf{do} \\
    \hspace*{2em} $\bd{x}_{k+1} = \Pi_C\bigl(\bd{x}_k - \gamma \nabla f(\bd{x}_k)\bigr)$ \\
    \textbf{end for}
\end{algorithmblock}
\begin{remark}\label{rem:pgd}
    \begin{itemize}
        \item If $\bb{X} = \bb{R}^n$, Algorithm~\ref{alg:pgd} reduces to
              standard gradient descent.
        \item Constraints are enforced via projection rather than penalties.
        \item The analysis parallels unconstrained gradient descent using
              Fej\'er monotonicity.
    \end{itemize}
\end{remark}
\begin{theorem}[Theorem A]\label{thm:pgd-main}
    Let $C \subset \bb{R}^n$ be nonempty, closed, and convex, and let
    $f$ be differentiable on an open set containing $C$.
    Assume that the problem
    \[
        \min_{\bd{x} \in C} f(\bd{x})
    \]
    is solvable.

    Let $\{\bd{x}_k\}$ be the sequence generated by projected gradient descent.
    Then
    \[
        f(\bd{x}_k) - \min_{\bd{x} \in C} f(\bd{x})
        \le
        \mathcal{O}\!\left(\frac{1}{k}\right),
    \]
    and
    \[
        \bd{x}_k \to \bd{x}^\ast,
        \qquad
        \bd{x}^\ast \in \arg\min_{\bd{x} \in C} f(\bd{x}).
    \]
\end{theorem}
\begin{proposition}[Optimality condition]\label{prop:optimality-C}
    Let $C \subset \bb{R}^n$ be nonempty, closed, and convex, and let
    $f$ be differentiable on an open set containing $C$.
    For a point $\bd{x}^\ast \in C$, the following statements are equivalent:
    \begin{enumerate}
        \item \[\bd{x}^\ast \in \arg\min_{\bd{x} \in C} f(\bd{x})\]
        \item
              \[
                  \bd{x}^\ast
                  =
                  \Pi_C\bigl(\bd{x}^\ast - \gamma \nabla f(\bd{x}^\ast)\bigr),
                  \quad \forall \gamma > 0.
              \]
        \item
              \[
                  \langle \bd{x} - \bd{x}^\ast,
                  \nabla f(\bd{x}^\ast) \rangle
                  \ge 0,
                  \quad \forall \bd{x} \in C.
              \]
    \end{enumerate}
\end{proposition}
\begin{proposition}[Acuteness property of projection]\label{prop:acuteness}
    Let $C \subset \bb{R}^n$ be nonempty, closed, and convex.
    For $\bd{x}_0 \in \bb{R}^n$ and $\bd{p} \in C$, the following
    statements are equivalent:
    \begin{enumerate}
        \item \[\bd{p} = \Pi_C(\bd{x}_0)\]
        \item
              \[
                  \langle \bd{x}_0 - \bd{p}, \bd{x} - \bd{p} \rangle \le 0,
                  \quad \forall \bd{x} \in C.
              \]
    \end{enumerate}
\end{proposition}

\begin{remark}
    The inequality states that the angle between the vectors
    $\bd{x}_0 - \bd{p}$ and $\bd{x} - \bd{p}$ is obtuse or right
    for every $\bd{x} \in C$.
    Geometrically, this means that the segment joining $\bd{x}_0$ to its
    projection $\bd{p}$ forms a supporting hyperplane to the set $C$ at
    $\bd{p}$.
\end{remark}
